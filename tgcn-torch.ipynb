{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c84b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import traceback\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities import rank_zero_info\n",
    "import models\n",
    "import tasks\n",
    "import utils.callbacks\n",
    "import utils.data\n",
    "import utils.logging\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9bcdaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'logger': True, 'enable_checkpointing': True, 'default_root_dir': None, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'num_nodes': 1, 'num_processes': None, 'devices': None, 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 1, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': None, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 50, 'accelerator': None, 'strategy': None, 'sync_batchnorm': False, 'precision': 32, 'enable_model_summary': True, 'num_sanity_val_steps': 2, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': True, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'data': 'tailing', 'model_name': 'TGCN', 'settings': 'supervised', 'log_path': None, 'send_email': False, 'batch_size': 64, 'seq_len': 5, 'pre_len': 3, 'split_ratio': 0.8, 'normalize': True, 'hidden_dim': 64, 'learning_rate': 0.001, 'weight_decay': 0.0015, 'loss': 'mse_with_regularizer'}\n",
      "E:\\Anaconda\\envs\\torchlg\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:262: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  rank_zero_warn(\n",
      "E:\\Anaconda\\envs\\torchlg\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:467: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "E:\\Anaconda\\envs\\torchlg\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type   | Params\n",
      "-------------------------------------\n",
      "0 | model     | TGCN   | 12.7 K\n",
      "1 | regressor | Linear | 195   \n",
      "-------------------------------------\n",
      "12.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.9 K    Total params\n",
      "0.051     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16812, 38, 30)\n",
      "(16812, 3, 30)\n",
      "(4198, 38, 30)\n",
      "(4198, 3, 30)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\torchlg\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': tensor(80490.1875, device='cuda:0'), 'RMSE': tensor(0.6527, device='cuda:0'), 'MAE': tensor(0.6272, device='cuda:0'), 'accuracy': tensor(-0.1786, device='cuda:0'), 'R2': tensor(-0.0064, device='cuda:0'), 'ExplainedVar': tensor(-0.0908, device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\torchlg\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c044c4354ea4419c85e4c303687f15ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': tensor(5318.9902, device='cuda:0'), 'RMSE': tensor(0.1678, device='cuda:0'), 'MAE': tensor(0.1220, device='cuda:0'), 'accuracy': tensor(0.6970, device='cuda:0'), 'R2': tensor(0.0600, device='cuda:0'), 'ExplainedVar': tensor(0.0600, device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\torchlg\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "E:\\Anaconda\\envs\\torchlg\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\checkpoint_connector.py:124: UserWarning: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at D:\\T-GCN\\T-GCN-PyTorch\\lightning_logs\\version_9\\checkpoints\\epoch=0-step=263.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16812, 38, 30)\n",
      "(16812, 3, 30)\n",
      "(4198, 38, 30)\n",
      "(4198, 3, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from checkpoint at D:\\T-GCN\\T-GCN-PyTorch\\lightning_logs\\version_9\\checkpoints\\epoch=0-step=263.ckpt\n",
      "E:\\Anaconda\\envs\\torchlg\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d1ebb4856c4f0f9617bcb87ba8c3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': tensor(5318.9902, device='cuda:0'), 'RMSE': tensor(0.1678, device='cuda:0'), 'MAE': tensor(0.1220, device='cuda:0'), 'accuracy': tensor(0.6970, device='cuda:0'), 'R2': tensor(0.0600, device='cuda:0'), 'ExplainedVar': tensor(0.0600, device='cuda:0')}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      ExplainedVar          0.06001746654510498\n",
      "           MAE              0.12197772413492203\n",
      "           R2              0.059998393058776855\n",
      "          RMSE              0.16779471933841705\n",
      "        accuracy            0.6970181465148926\n",
      "        val_loss              5318.990234375\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "DATA_PATHS = {\n",
    "    \"tailing\": {\"feat\": \"data/3611817550_feature_matrix_X.csv\", \"adj\": \"data/3611817550_adj.csv\"},\n",
    "}\n",
    "\n",
    "\n",
    "def get_model(args, dm):\n",
    "    model = None\n",
    "    if args.model_name == \"GCN\":\n",
    "        model = models.GCN(adj=dm.adj, input_dim=args.seq_len, output_dim=args.hidden_dim)#input_dim=args.seq_len*5+args.pre_len*4+1\n",
    "    if args.model_name == \"GRU\":\n",
    "        model = models.GRU(input_dim=dm.adj.shape[0], hidden_dim=args.hidden_dim)#input_dim=dm.adj.shape[0]\n",
    "    if args.model_name == \"TGCN\":\n",
    "        model = models.TGCN(adj=dm.adj, hidden_dim=args.hidden_dim)\n",
    "    return model\n",
    "\n",
    "def get_task(args, model, dm):\n",
    "    task = getattr(tasks, args.settings.capitalize() + \"ForecastTask\")(\n",
    "        model=model, feat_max_val=dm.feat_max_val, **vars(args)\n",
    "    )\n",
    "    return task\n",
    "\n",
    "\n",
    "def get_callbacks(args):\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"train_loss\")\n",
    "    plot_validation_predictions_callback = utils.callbacks.PlotValidationPredictionsCallback(monitor=\"train_loss\")\n",
    "    callbacks = [\n",
    "        checkpoint_callback,\n",
    "        plot_validation_predictions_callback,\n",
    "    ]\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def main_supervised(args):\n",
    "    dm = utils.data.SpatioTemporalCSVDataModule(\n",
    "        feat_path=DATA_PATHS[args.data][\"feat\"], adj_path=DATA_PATHS[args.data][\"adj\"], **vars(args)\n",
    "    )\n",
    "    model = get_model(args, dm)\n",
    "    task = get_task(args, model, dm)\n",
    "    callbacks = get_callbacks(args)\n",
    "    trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, gpus=1, max_epochs=10)#gpus=1,\n",
    "    trainer.fit(task, dm)\n",
    "    results = trainer.validate(datamodule=dm)\n",
    "    return results\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    rank_zero_info(vars(args))\n",
    "    results = globals()[\"main_\" + args.settings](args)\n",
    "    return results\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--data\", type=str, help=\"The name of the dataset\", choices=(\"tailing\"), default=\"tailing\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name\",\n",
    "        type=str,\n",
    "        help=\"The name of the model for spatiotemporal prediction\",\n",
    "        choices=(\"GCN\", \"GRU\", \"TGCN\"),\n",
    "        default=\"TGCN\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--settings\",\n",
    "        type=str,\n",
    "        help=\"The type of settings, e.g. supervised learning\",\n",
    "        choices=(\"supervised\",),\n",
    "        default=\"supervised\",\n",
    "    )\n",
    "    parser.add_argument(\"--log_path\", type=str, default=None, help=\"Path to the output console log file\")\n",
    "    parser.add_argument(\"--send_email\", \"--email\", action=\"store_true\", help=\"Send email when finished\")\n",
    "    temp_args, _ = parser.parse_known_args()\n",
    "\n",
    "    parser = getattr(utils.data, temp_args.settings.capitalize() + \"DataModule\").add_data_specific_arguments(parser)\n",
    "    parser = getattr(models, temp_args.model_name).add_model_specific_arguments(parser)\n",
    "    parser = getattr(tasks, temp_args.settings.capitalize() + \"ForecastTask\").add_task_specific_arguments(parser)\n",
    "    \n",
    "    args = parser.parse_args(args=[])\n",
    "    # utils.logging.format_logger(pl._logger)\n",
    "    if args.log_path is not None:\n",
    "        utils.logging.output_logger_to_file(pl._logger, args.log_path)\n",
    "\n",
    "    try:\n",
    "        results = main(args)\n",
    "    except:  # noqa: E722\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e1c1a-d871-474a-a62d-ad9932f6314e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
